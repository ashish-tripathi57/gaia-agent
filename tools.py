from langchain_tavily import TavilySearch
from langchain_core.tools import tool
from langchain_core.tools import Tool
from langchain_community.document_loaders import WikipediaLoader
import wikipedia
import requests
from bs4 import BeautifulSoup
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate

import os
import base64
# from playwright.sync_api import sync_playwright
from langchain_experimental.utilities import PythonREPL
import subprocess
import pandas as pd
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@tool
def data_tool(query: str, task_id: str) -> str:
    """
    Executes a natural language query on a DataFrame loaded from an Excel file associated with the given task_id.

    Args:
        query (str): The natural language query to execute on the DataFrame.
        task_id (str): The identifier used to locate the corresponding Excel file (./downloaded_files/{task_id}.xlsx).

    Returns:
        str: The response generated by the language model after processing the query on the DataFrame.
    """

    file_path = f"./downloaded_files/{task_id}.xlsx"
    logger.info(f"data_tool called with query='{query}'")
    df = pd.read_excel(file_path)

    if "GOOGLE_API_KEY" not in os.environ:
        os.environ["GOOGLE_API_KEY"] = os.environ["GEMINI_API_KEY"]
    
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0,
        max_tokens=None,
        timeout=60,  # Added a timeout
        max_retries=2,
    )
    agent = create_pandas_dataframe_agent(llm, df, verbose=True, allow_dangerous_code=True)
    response = agent.invoke(query)
    return response

@tool
def run_python(task_id: str) -> str:
    """
    Executes a Python script identified by the given task_id and returns its output.

    Args:
        task_id (str): The identifier used to locate the corresponding Python file (./downloaded_files/{task_id}.py).

    Returns:
        str: The standard output from executing the Python script, or an error message if execution fails.
    """
    logger.info(f"run_python called")
    result = subprocess.run(["python", f"./downloaded_files/{task_id}.py"], capture_output=True, text=True)
    return result.stdout.strip()
    

# repl_tool = Tool(
#     name="python_repl",
#     description="A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.",
#     func=PythonREPL().run,
# )

@tool
def audio_model(query: str, task_id: str) -> str:
    """
    Processes an audio query by sending both a text prompt and an audio file (associated with the given task_id)
    to a generative AI model, and returns the model's response.

    Args:
        query (str): The text prompt or question for the model.
        task_id (str): The identifier used to locate the corresponding audio file (MP3) in the downloaded_files directory.

    Returns:
        str: The response generated by the AI model based on the provided text and audio.
    """

    logger.info(f"audio_model called with query='{query}'")

    if "GOOGLE_API_KEY" not in os.environ:
        os.environ["GOOGLE_API_KEY"] = os.environ["GEMINI_API_KEY"]
    
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0,
        max_tokens=None,
        timeout=60,  # Added a timeout
        max_retries=2,
    )

    audio_file_path = f"./downloaded_files/{task_id}.mp3"
    audio_mime_type = "audio/mpeg"


    with open(audio_file_path, "rb") as audio_file:
        encoded_audio = base64.b64encode(audio_file.read()).decode("utf-8")

    message = HumanMessage(
        content=[
            {"type": "text", "text": query},
            {
                "type": "media",
                "data": encoded_audio,  # Use base64 string directly
                "mime_type": audio_mime_type,
            },
        ]
    )
    response = llm.invoke([message])  # Uncomment to run
    return response

    

@tool
def visual_model(query: str, task_id: str) -> str:
    """
    Processes a visual query by sending both a text prompt and an image (associated with the given task_id)
    to a generative AI model, and returns the model's response.

    Args:
        query (str): The text prompt or question for the model.
        task_id (str): The identifier used to locate the corresponding image file (PNG) in the downloaded_files directory.

    Returns:
        str: The response generated by the AI model based on the provided text and image.
    """

    logger.info(f"visual_model called with query='{query}'")
    if "GOOGLE_API_KEY" not in os.environ:
        os.environ["GOOGLE_API_KEY"] = os.environ["GEMINI_API_KEY"]
    
    llm_gemma = ChatGoogleGenerativeAI(
        model="gemma-3-27b-it",
        temperature=0,
        max_tokens=None,
        timeout=60,  # Added a timeout
        max_retries=2,
    )


    image_file_path = f"./downloaded_files/{task_id}.png"

    with open(image_file_path, "rb") as image_file:
        encoded_image = base64.b64encode(image_file.read()).decode("utf-8")

    message_local = HumanMessage(
        content=[
            {"type": "text", "text": f"{query}"},
            {"type": "image_url", "image_url": f"data:image/png;base64,{encoded_image}"},
        ]
    )
    result = llm_gemma.invoke([message_local])
    return result


search_tool = TavilySearch(
    max_results=2,
    # topic="general",    
    # time_range="week",
    # include_domains=None,
    # exclude_domains=None
)


# Define your desired data structure.
class ImprovedQuery(BaseModel):
    query1: str = Field(description="An improved query version 1")
    # query2: str = Field(description="An improved query version 2")
    # query3: str = Field(description="An improved query version 3")
    # query4: str = Field(description="An improved query version 4")
    # query5: str = Field(description="An improved query version 5")

@tool
def web_search(query: str) -> str:
    """Search the web for a query and return maximum 2 results.
    
    Args:
        query: The search query."""
    
    logger.info(f"web_search called with query='{query}'")
    # alternative_queries = generate_improved_queries(query)
    alternative_queries = {}
    alternative_queries['query'] = query
    # import pdb;pdb.set_trace()
    search_results = []
    for key, val in alternative_queries.items():
        search_results.append(search_tool.invoke(val))
    # print(f"Search results: {search_results} \n type: {type(search_results)}")
    return {"search_results": str(search_results)}

def generate_improved_queries(query: str) -> str:
    """
    Generate one improved versions of a given search query using a language model.

    Args:
        query (str): The original search query to be improved.

    Returns:
        str: A JSON object containing five improved query versions.
    """
    if "GOOGLE_API_KEY" not in os.environ:
        os.environ["GOOGLE_API_KEY"] = os.environ["GEMINI_API_KEY"]
    
    llm_gemma = ChatGoogleGenerativeAI(
        model="gemma-3-27b-it",
        temperature=0,
        max_tokens=None,
        timeout=60,  # Added a timeout
        max_retries=2,
    )

    # Set up a parser + inject instructions into the prompt template.
    parser = JsonOutputParser(pydantic_object=ImprovedQuery)
    prompt = PromptTemplate(
        template="Give 1 improved version of this search query: {query}\n.\n{format_instructions}\n",
        input_variables=["query"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )

    chain = prompt | llm_gemma | parser

    return chain.invoke({"query": query})


@tool
def wiki_search(query: str) -> str:
    """Search Wikipedia for a query and return maximum 2 results.
    
    Args:
        query: The search query."""
    
    logger.info(f"wiki_search called with query='{query}'")
    search_docs = WikipediaLoader(query=query, load_max_docs=2).load()
    # print(f"Search results: {search_docs}")
    formatted_search_docs = "\n\n---\n\n".join(
        [
            # f'<Document source="{doc.metadata["source"]}" page="{doc.metadata.get("page", "")}"/>\n{doc.page_content}\n</Document>'
            f'<Document source="{doc.metadata["source"]}" page="{doc.metadata.get("page", "")}"/>\n</Document>'
            for doc in search_docs
        ])
    return {"wiki_results": formatted_search_docs}


@tool
def wikipedia_search_html(query: str) -> str:
    """
    Search Wikipedia for a given query, retrieve the corresponding page's HTML content,
    clean it by removing unnecessary elements (such as styles, scripts, references, infoboxes, etc.),
    and return a simplified HTML string containing only the main content.

    Args:
        query (str): The search query for the Wikipedia page.

    Returns:
        str: Cleaned HTML string of the Wikipedia page's main content, or an empty string if not found.
    """
    
    logger.info(f"wikipedia_search_html called with query='{query}'")
    # Step 1: Get Wikipedia HTML
    page = wikipedia.page(query)
    html = page.html()

    # Step 2: Parse HTML
    soup = BeautifulSoup(html, "html.parser")
    content_div = soup.find("div", class_="mw-parser-output")
    # content_div = soup.find("table", class_="wikitable")
    if not content_div:
        return ""

    # Step 3: Find all tags to remove (style, script, sup, infobox, etc.)
    to_decompose = []
    for tag in content_div.find_all():
        tag_classes = tag.get("class", [])
        if (
            tag.name in ["style", "script", "sup"]
            or any(cls in ["infobox", "navbox", "reference"] for cls in tag_classes)
        ):
            to_decompose.append(tag)

    # Remove them after collecting
    for tag in to_decompose:
        tag.decompose()

    # Step 4: Unwrap all tags except allowed ones
    allowed_tags = {"ul", "li", "table", "tr", "td", "th"}
    to_unwrap = [tag for tag in content_div.find_all() if tag.name not in allowed_tags]

    for tag in to_unwrap:
        tag.unwrap()

    # Step 5: Return cleaned HTML string
    return str(content_div)


@tool
def website_scrape(url: str) -> str:
    """
    Scrape the given website URL and return all extracted text content.

    Args:
        url (str): The URL of the website to scrape.

    Returns:
        str: The plain text content extracted from the website's HTML.
    """

    logger.info(f"website_scrape called with url='{url}'")
    # with sync_playwright() as p:
    #     browser = p.chromium.launch(headless=True)
    #     page = browser.new_page()
    #     page.goto(url)
    #     html_content = page.content()
    #     browser.close()

    # url = "https://en.wikipedia.org/wiki/"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    # Extract the infobox table
    # infobox = soup.find("table", {"class": "infobox"})

    # Extract text from the website
    text = soup.get_text()

    return text

if __name__ == "__main__":

    # Example usage
    # query = "Mercedes Sosa"
    # results = website_scrape.invoke({"url":"https://en.wikipedia.org/wiki/", "question":query})
    # results = wikipedia_search_html.invoke({"query": query})
    # results = wiki_search.invoke({"query": "Wikipedia featured articles promoted in november 2016"})
    # results = web_search.invoke({"query": "featured article dinosaur english wikipedia november 2016"})
    # results = website_scrape.invoke({"url":"https://en.wikipedia.org/wiki/Wikipedia:Featured_article_candidates/Giganotosaurus/archive1"})
    # results = visual_model.invoke({"query": "Review the chess position provided in the image. It is black's turn. Provide the correct next move for black which guarantees a win. Please provide your response in algebraic notation.", "task_id": "cca530fc-4052-43b2-b130-b30968d8aa44"})
    # results = audio_model.invoke({"query": """Hi, I'm making a pie but I could use some help with my shopping list. I have everything I need for the crust, but I'm not sure about the filling. I got the recipe from my friend Aditi, but she left it as a voice memo and the speaker on my phone is buzzing so I can't quite make out what she's saying. Could you please listen to the recipe and list all of the ingredients that my friend described? I only want the ingredients for the filling, as I have everything I need to make my favorite pie crust. I've attached the recipe as Strawberry pie.mp3.

    # In your response, please only list the ingredients, not any measurements. So if the recipe calls for "a pinch of salt" or "two cups of ripe strawberries" the ingredients on the list would be "salt" and "ripe strawberries".

    # Please format your response as a comma separated list of ingredients. Also, please alphabetize the ingredients.""", "task_id": "99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3"})
    # results = audio_model.invoke({"query": """Hi, I'm making a pie but I could use some help with my shopping list. I have everything I need for the crust, but I'm not sure about the filling. I got the recipe from my friend Aditi, but she left it as a voice memo and the speaker on my phone is buzzing so I can't quite make out what she's saying. Could you please listen to the recipe and list all of the ingredients that my friend described? I only want the ingredients for the filling, as I have everything I need to make my favorite pie crust. I've attached the recipe as Strawberry pie.mp3.

    # In your response, please only list the ingredients, not any measurements. So if the recipe calls for "a pinch of salt" or "two cups of ripe strawberries" the ingredients on the list would be "salt" and "ripe strawberries".

    # Please format your response as a comma separated list of ingredients. Also, please alphabetize the ingredients.""", "task_id": "99c9cc74-fdc8-46c6-8f8d-3ce2d3bfeea3"})
    # results = run_python.invoke({"task_id":"f918266a-b3e0-4914-865d-4faa564f1aef"})
    # results = read_excel_file.invoke({"task_id":"7bd855d8-463d-4ed5-93ca-5fe35145f733", "sheet_name": 0})
    results = data_tool.invoke({"query":"The attached Excel file contains the sales of menu items for a local fast-food chain. What were the total sales that the chain made from food (not including drinks)? Express your answer in USD with two decimal places.", "task_id":"7bd855d8-463d-4ed5-93ca-5fe35145f733"})
    print("result:", results)
    
    # Example usage of TavilySearch
    # search_results = search_tool.search("Python programming language")
    # print(search_results)

    
